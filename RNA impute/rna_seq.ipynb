{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "train_data=pd.read_csv(\"test_data.csv\")\n",
    "#print(train_data)\n",
    "train_data=train_data.T\n",
    "train_data.to_csv(\"testT_data.csv\")\n",
    "data=train_data.values\n",
    "data_values=data.T  #进行转置？\n",
    "#print(train_data)\n",
    "adata=sc.read_csv(\"testT_data.csv\")#应该进行装置\n",
    "adata=adata[1:201]\n",
    "print(type(data))\n",
    "a,gene_num=adata.shape\n",
    "sc.pp.filter_cells(adata, min_counts=1)\n",
    "adata.raw = adata.copy()\n",
    "adata.obs['size_factors'] = adata.obs.n_counts / np.median(adata.obs.n_counts)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.scale(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#编码方式\n",
    "class seq_dataset(Dataset):\n",
    "    def __init__(self,load_data):\n",
    "        self.data = load_data\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    def __len__(self,):\n",
    "        return len(self.data)\n",
    "RNA=seq_dataset(data_values)\n",
    "train_RNA_dataloader=DataLoader(RNA,batch_size=32,shuffle=True)\n",
    "count_mtx = torch.tensor(adata.X)\n",
    "count_mtx_raw = torch.tensor(adata.raw.X)\n",
    "size_factor = torch.tensor(adata.obs.size_factors.values)\n",
    "dataset = TensorDataset(count_mtx, size_factor,count_mtx_raw)\n",
    "#print(dataset)\n",
    "train1_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(mat):\n",
    "    if type(mat) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(mat.weight,gain=3)\n",
    "        print(\"Weight:\",mat.weight)\n",
    "        mat.bias.data.fill_(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mean_activation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mean_activation,self).__init__()\n",
    "    def forward(self,input):\n",
    "        return torch.exp(input)\n",
    "\n",
    "class dispersion_activiation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dispersion_activiation,self).__init__()\n",
    "    def forward(self,input):\n",
    "        return torch.exp(input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class auto_encoder(nn.Module):\n",
    "    def __init__( self,gene_num,hidden_dim):\n",
    "        super(auto_encoder,self).__init__()\n",
    "        self.gene_num = gene_num\n",
    "        print(\"gene_num: \" ,gene_num)\n",
    "\n",
    "        self.autoencoder_stack=nn.Sequential(\n",
    "            nn.Linear(gene_num,hidden_dim[0]),\n",
    "            nn.BatchNorm1d(hidden_dim[0],eps=1e-2,affine=False), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim[0],hidden_dim[1]),\n",
    "            nn.BatchNorm1d(hidden_dim[1],eps=1e-2,affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim[1],hidden_dim[2]),\n",
    "            nn.BatchNorm1d(hidden_dim[2],eps=1e-2,affine=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mean=nn.Sequential(\n",
    "            nn.Linear(hidden_dim[2],gene_num),\n",
    "            mean_activation()\n",
    "        )\n",
    "        self.pi=nn.Sequential(\n",
    "            nn.Linear(hidden_dim[2],gene_num),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.theta=nn.Sequential(\n",
    "            nn.Linear(hidden_dim[2],gene_num),\n",
    "            dispersion_activiation()\n",
    "        )\n",
    "\n",
    "    def forward(self, input, size_factor):\n",
    "        size_factor = size_factor.view(-1, 1)#?\n",
    "        size_factor = size_factor.repeat(1, self.gene_num)\n",
    "        #ae_out = input * size_factor\n",
    "        ae_out = self.autoencoder_stack(input) #?\n",
    "        #print(\"AE:  \", ae_out)\n",
    "        mean = self.mean(ae_out) * size_factor\n",
    "        #print(\"MEAN:  \", mean)\n",
    "        theta = self.theta(ae_out)\n",
    "        pi = self.pi(ae_out)\n",
    "        return mean, theta, pi\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nan2inf(x):\n",
    "    return torch.where(torch.isnan(x), torch.zeros_like(x) + np.inf, x)\n",
    "class NB(torch.nn.Module):\n",
    "    def __init__(self, scale_factor=1.0):\n",
    "        super(NB, self).__init__()\n",
    "        self.eps = 1e-10\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, theta, y_true, y_pred, mean=True):\n",
    "        y_pred = y_pred * self.scale_factor\n",
    "        t1 = torch.lgamma(theta + self.eps) + torch.lgamma(y_true + 1.0) - torch.lgamma(y_true + theta + self.eps)\n",
    "        t2 = (theta + y_true) * torch.log(1.0 + (y_pred / (theta + self.eps))) + (\n",
    "                y_true * (torch.log(theta + self.eps) - torch.log(y_pred + self.eps)))\n",
    "\n",
    "        final = t1 + t2\n",
    "        final = _nan2inf(final)\n",
    "\n",
    "        if mean:\n",
    "            final = torch.mean(final)\n",
    "\n",
    "        return final\n",
    "class ZINB(NB):\n",
    "    def __init__(self, scale_factor=1.0, ridge_lambda=0.0):\n",
    "        super().__init__(scale_factor=scale_factor)\n",
    "        self.ridge_lambda = ridge_lambda\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, pi, theta, y_true, y_pred, mean=True):\n",
    "        nb_case = super().forward(theta, y_true, y_pred, mean=False) - torch.log(1.0 - pi + self.eps)\n",
    "\n",
    "        y_pred = y_pred * self.scale_factor\n",
    "        # theta = torch.minimum(theta, torch.tensor(1e6))\n",
    "\n",
    "        zero_nb = torch.pow(theta / (theta + y_pred + self.eps), theta)\n",
    "        zero_case = -torch.log(pi + ((1.0 - pi) * zero_nb) + self.eps)\n",
    "        result = torch.where(torch.lt(y_true, 1e-8), zero_case, nb_case)\n",
    "\n",
    "        if self.ridge_lambda > 0:\n",
    "            ridge = self.ridge_lambda * torch.square(pi)\n",
    "            result += ridge\n",
    "\n",
    "        if mean:\n",
    "            result = torch.mean(result)\n",
    "\n",
    "        result = _nan2inf(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "epochs = 180\n",
    "grad_clip_val = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#gene_num=count_mtx_raw.shape[1]\n",
    "model = auto_encoder(gene_num=gene_num, hidden_dim=(64, 32, 64))\n",
    "model.apply(weights_init)#不完整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = ZINB()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, epochs / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,model,loss,optimizer):\n",
    "    #size_data=len(dataloader.dataset)\n",
    "    for batch, (X, size, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "    # Predict, and calculate loss\n",
    "        mean, theta, pi = model(y, size)\n",
    "        #loss_val = loss(mean, theta, pi, y)\n",
    "        loss_val= loss (pi,theta,y,mean,mean=True)\n",
    "        loss_val.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip_val)\n",
    "        optimizer.step()\n",
    "        if batch % 50 == 0:\n",
    "            #loss, curr = loss_val, batch * len(X)\n",
    "            print(f\"loss: {loss_val}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in np.arange(epochs):\n",
    "    print(f\"Epoch {iter}\\n-------------------------------\")\n",
    "    train(train1_dataloader,model,loss_fn,optimizer)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, theta, pi = model(count_mtx_raw, size_factor)\n",
    "print(mean)\n",
    "mean_value=mean.detach().numpy()\n",
    "#print(theta)\n",
    "#print(pi)\n",
    "#print(mean.shape,train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def impute_zero(mean, previous_data):\n",
    "    imputed=previous_data.copy()\n",
    "    print(imputed)\n",
    "    for item in np.arange(imputed.shape[0]):\n",
    "        for ele in np.arange(imputed.shape[1]):\n",
    "            if imputed[item][ele]==0:\n",
    "                imputed[item][ele]=mean[item][ele]\n",
    "    return imputed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_res=impute_zero(mean,data)\n",
    "print(imputed_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_diff(previous,file_path):\n",
    "    true_data=pd.read_csv(file_path)\n",
    "    true_data=np.array(true_data)\n",
    "    true_data=true_data.T\n",
    "    dist=0\n",
    "    for item in np.arange(previous.shape[0]):\n",
    "        for ele in np.arange(previous.shape[1]):\n",
    "            if previous[item][ele]==0:\n",
    "                res=true_data[item][ele]\n",
    "                dist=dist+res\n",
    "    print(\"Previous Value Sum: \",dist)\n",
    "def calculate_distance(mat,file_path,imputed):\n",
    "    distance = 0;\n",
    "    count_pre,count_after=0,0\n",
    "    true_data=pd.read_csv(file_path)\n",
    "    true_data=np.array(true_data)\n",
    "    true_data=true_data.T\n",
    "    print(data.shape,true_data.shape)\n",
    "    for item in np.arange(mat.shape[0]):\n",
    "        for ele in np.arange(mat.shape[1]):\n",
    "            if mat[item][ele]==0:\n",
    "                count_pre+=1\n",
    "                if np.round(imputed[item][ele])==0:\n",
    "                    count_after+=1\n",
    "                res=np.round(imputed[item][ele]-true_data[item][ele])\n",
    "                #print(mat[item][ele]-true_data[item][ele])\n",
    "                distance+=np.abs(res)\n",
    "    print(\"Dropout Previous :\",count_pre/(mat.shape[0]*mat.shape[1]))\n",
    "    print(\"Dropout Imputed :\",count_after/(mat.shape[0]*mat.shape[1]))\n",
    "    print(\"Imputed Value Sum:\",distance)\n",
    "    return distance\n",
    "dist=calculate_distance(data,\"test_truedata.csv\",mean_value)\n",
    "previous_diff(data,\"test_truedata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对大数据集进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.read_csv(\"data.csv\")\n",
    "test_data=data_test.T\n",
    "test_data.to_csv(\"data4test.csv\")\n",
    "finaldata=test_data.values\n",
    "data_values=finaldata.T  #进行转置？\n",
    "data2test=sc.read_csv(\"data4test.csv\")\n",
    "data2test=data2test[1:data2test.shape[0]]\n",
    "print(data2test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(data2test, min_counts=1)\n",
    "data2test.raw = data2test.copy()\n",
    "data2test.obs['size_factors'] = data2test.obs.n_counts / np.median(data2test.obs.n_counts)\n",
    "sc.pp.log1p(data2test)\n",
    "sc.pp.scale(data2test)\n",
    "count_mtx_raw_1 = torch.tensor(data2test.raw.X)\n",
    "size_factor_1 = torch.tensor(data2test.obs.size_factors.values)\n",
    "means, theta, pi = model(count_mtx_raw_1, size_factor_1)\n",
    "mean_value_final=means.detach().numpy()\n",
    "print(mean_value_final.shape,test_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=impute_zero(mean_value_final,finaldata)\n",
    "final_res=pd.DataFrame(results.T)\n",
    "final_res.to_csv(\"results.csv\",index=0,header=0)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2345e6128660d800caeeaf1f3a6936fcd09960590a8a89cf9fb390fc735dae0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
